# slidedeckai/agents/core_agents.py - FIXED LAYOUT VALIDATION
"""
CRITICAL FIXES:
1. Remove hardcoded fallbacks
2. Strengthen layout validation
3. Ensure unique subtitles always
4. Better diversity enforcement
"""
import logging
import json
from typing import List, Dict, Optional, Set
from pydantic import BaseModel, Field
from openai import OpenAI

logger = logging.getLogger(__name__)

class SearchQuery(BaseModel):
    query: str
    purpose: str
    expected_source_type: str = "research"

class PlaceholderContentSpec(BaseModel):
    placeholder_idx: int
    placeholder_type: str
    content_type: str
    content_description: str
    search_queries: List[SearchQuery] = Field(default_factory=list)
    position_group: str = ""
    role: str = "content"
    dimensions: Dict = Field(default_factory=dict)

class SectionPlan(BaseModel):
    section_title: str
    section_purpose: str
    layout_type: str
    layout_idx: int
    layout_story: str
    placeholder_specs: List[PlaceholderContentSpec]
    total_search_queries: int = 0
    enforced_content_type: str = "bullets"

class ResearchPlan(BaseModel):
    query: str
    analysis: Dict
    sections: List[SectionPlan]
    search_mode: str = "normal"
    total_queries: int = 0
    template_info: Dict = Field(default_factory=dict)


class PlanGeneratorOrchestrator:
    """FIX #1 & #6: Remove fallbacks, strengthen validation"""
    
    def __init__(self, api_key: str, search_mode: str = 'normal'):
        self.api_key = api_key
        self.search_mode = search_mode
        self.client = OpenAI(api_key=api_key)
        self.model = "gpt-4o-mini"
        self.used_topics: Set[str] = set()
    
    def generate_plan(self, user_query: str, template_layouts: Dict, 
                     num_sections: Optional[int] = None, extracted_content: Optional[str] = None) -> ResearchPlan:
        """Existing logic with FIX #1: Validate layouts upfront. Added support for extracted content."""
        
        logger.info("ðŸ¤– Starting FULLY DYNAMIC planning...")
        
        # âœ… FIX #1: Validate layouts FIRST
        template_layouts = {int(k): v for k, v in template_layouts.items()}
        
        if not template_layouts:
            raise ValueError("No layouts found in template!")
        
        # STEP 1: Deep analysis (using content if available)
        analysis = self._llm_deep_analysis(user_query, extracted_content)
        logger.info(f"  ðŸ§  Analysis complete")
        
        # STEP 2: Determine section count
        target_sections = num_sections if num_sections else self._llm_determine_section_count(
            user_query, analysis, extracted_content
        )
        logger.info(f"  ðŸ“Š Target: {target_sections} sections")
        
        # STEP 3: Analyze template
        template_capabilities = self._dynamic_template_analysis(template_layouts)
        logger.info(f"  ðŸ” Template: {len(template_capabilities['usable_layouts'])} layouts")
        
        # âœ… FIX #1: Ensure we have usable layouts
        if len(template_capabilities['usable_layouts']) == 0:
            raise ValueError("No usable layouts found in template!")
        
        # STEP 4: Generate topics
        section_topics = self._llm_generate_all_topics(
            user_query, analysis, target_sections, template_capabilities, extracted_content
        )
        logger.info(f"  ðŸ“ Generated {len(section_topics)} unique topics")
        
        # STEP 5: Match topics to layouts WITH VALIDATION
        section_blueprints = self._llm_match_topics_to_layouts_validated(
            section_topics, template_capabilities, template_layouts
        )
        
        # STEP 6: Generate detailed plans
        sections = []
        for i, blueprint in enumerate(section_blueprints, 1):
            section = self._generate_detailed_slide_plan(
                section_num=i,
                blueprint=blueprint,
                query=user_query,
                template_layouts=template_layouts,
                extracted_content=extracted_content
            )
            sections.append(section)
            logger.info(f"  âœ… Slide {i}: {section.section_title}")
        
        plan = ResearchPlan(
            query=user_query,
            analysis=analysis,
            sections=sections,
            search_mode=self.search_mode,
            total_queries=sum(s.total_search_queries for s in sections),
            template_info=template_capabilities
        )
        
        logger.info(f"âœ… Plan: {len(sections)} slides")
        return plan
    
    def _llm_match_topics_to_layouts_validated(self, topics: List[Dict], 
                                                capabilities: Dict,
                                                template_layouts: Dict) -> List[Dict]:
        """
        FIX #1 & #6: STRICT validation with NO fallbacks
        """
        
        valid_indices = sorted(capabilities['usable_layouts'])
        min_idx = min(valid_indices)
        max_idx = max(valid_indices)
        
        logger.info(f"  Valid layout range: {min_idx} to {max_idx}")
        
        prompt = f"""You have {len(topics)} slide topics and these template capabilities:

CRITICAL CONSTRAINTS:
- Layout indices MUST be between {min_idx} and {max_idx} (inclusive)
- These are the ONLY valid indices: {valid_indices}
- Do NOT use any index outside this range
- RETURN EXACTLY {len(topics)} assignments

Topics:
{json.dumps(topics, indent=2)}

Template layouts available:
- Chart-capable layouts: {capabilities['chart_capable']}
- Table-capable layouts: {capabilities['table_capable']}
- Multi-content layouts: {capabilities['multi_content']}
- All usable layouts: {valid_indices}

Your task:
1. For each topic, select the BEST layout from {valid_indices}
2. Use chart layouts for chart content
3. Use table layouts for table content
4. Use multi-content for icon grids
5. Rotate through layouts - USE ALL AVAILABLE
6. ENSURE diversity - avoid 3 consecutive same layouts

Return ONLY valid JSON:
{{
  "assignments": [
    {{
      "topic_index": 0,
      "title": "topic title",
      "layout_idx": {min_idx},
      "content_type": "chart",
      "reasoning": "why this layout"
    }}
  ]
}}

REMEMBER: layout_idx MUST be an integer between {min_idx} and {max_idx}."""
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "You are a layout expert. Match topics to optimal layouts. Return only valid JSON."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.5 + (attempt * 0.1),  # Increase temp on retry
                    max_tokens=1500,
                    response_format={"type": "json_object"}
                )
                
                data = json.loads(response.choices[0].message.content)
                assignments = data.get('assignments', [])
                
                # âœ… FIX #6: STRICT VALIDATION
                validated = []
                for i, a in enumerate(assignments):
                    if i >= len(topics):
                        break
                    
                    layout_idx = a.get('layout_idx')
                    
                    # Ensure integer
                    if not isinstance(layout_idx, int):
                        try:
                            layout_idx = int(layout_idx)
                        except:
                            logger.error(f"âŒ Invalid layout_idx type: {type(layout_idx)}")
                            raise ValueError(f"Layout index must be integer, got {type(layout_idx)}")
                    
                    # âœ… FIX #1: STRICT validation - NO fallback
                    if layout_idx not in valid_indices:
                        logger.error(f"âŒ Invalid layout_idx {layout_idx}, valid: {valid_indices}")
                        raise ValueError(f"Layout {layout_idx} not in valid range")
                    
                    validated.append({
                        'title': topics[i]['title'],
                        'purpose': topics[i]['purpose'],
                        'layout_idx': layout_idx,
                        'content_type': a.get('content_type', topics[i].get('best_content', 'bullets'))
                    })
                
                # âœ… FIX #6: Ensure we have ALL assignments
                if len(validated) != len(topics):
                    raise ValueError(f"Expected {len(topics)} assignments, got {len(validated)}")
                
                logger.info(f"    LLM matched {len(validated)} topics to layouts")
                return validated
                
            except Exception as e:
                logger.error(f"    Attempt {attempt + 1} failed: {e}")
                if attempt == max_retries - 1:
                    raise RuntimeError(f"Failed to match topics to layouts after {max_retries} attempts: {e}")
        
        # Should never reach here
        raise RuntimeError("Layout matching failed unexpectedly")
    
    def _generate_detailed_slide_plan(self, section_num: int, blueprint: Dict,
                                   query: str, template_layouts: Dict,
                                   extracted_content: Optional[str] = None) -> SectionPlan:
        """FIX #3: GUARANTEE unique subtitles with retry logic"""
        
        layout_idx = blueprint['layout_idx']
        
        if not isinstance(layout_idx, int):
            layout_idx = int(layout_idx)
        
        # âœ… FIX #1: Validate layout exists
        if layout_idx not in template_layouts:
            raise ValueError(f"Layout {layout_idx} not found in template")
        
        layout = template_layouts[layout_idx]
        
        specs = []
        used_subtitles = set()
        
        # TITLE
        specs.append(PlaceholderContentSpec(
            placeholder_idx=0,
            placeholder_type="TITLE",
            content_type="text",
            content_description=blueprint['title'],
            search_queries=[],
            position_group="title",
            role="title"
        ))
        
        # SUBTITLES - FIX #3: GUARANTEE uniqueness
        subtitle_phs = layout['placeholders'].get('subtitles', [])
        for ph in subtitle_phs:
            heading = self._llm_generate_subtitle_guaranteed_unique(
                blueprint['purpose'],
                ph.get('position_group', ''),
                blueprint['content_type'],
                used_subtitles
            )
            
            used_subtitles.add(heading)
            
            specs.append(PlaceholderContentSpec(
                placeholder_idx=ph['idx'],
                placeholder_type=ph['type'],
                content_type="subtitle",
                content_description=heading,
                search_queries=[],
                position_group=ph.get('position_group', ''),
                role="subtitle",
                dimensions={
                    'width': ph.get('width', 0),
                    'height': ph.get('height', 0),
                    'area': ph.get('area', 0)
                }
            ))
        
        # CONTENT
        content_phs = layout['placeholders']['content']
        self._assign_content_dynamically(
            specs, content_phs, blueprint, query, extracted_content
        )
        
        return SectionPlan(
            section_title=blueprint['title'],
            section_purpose=blueprint['purpose'],
            layout_type=layout['layout_type'],
            layout_idx=layout_idx,
            layout_story=layout.get('layout_story', ''),
            placeholder_specs=specs,
            total_search_queries=sum(len(s.search_queries) for s in specs),
            enforced_content_type=blueprint['content_type']
        )
    
    def _llm_generate_subtitle_guaranteed_unique(self, purpose: str, position: str, 
                                                  content_type: str, used_subtitles: set) -> str:
        """
        FIX #3: GUARANTEE unique subtitle with strict retry logic
        """
        
        max_attempts = 5
        
        for attempt in range(max_attempts):
            prompt = f"""Generate a SHORT heading (2-4 words) for a slide section:

Slide purpose: {purpose}
Position: {position}
Content type: {content_type}

ALREADY USED (DO NOT REPEAT): {', '.join(used_subtitles) if used_subtitles else 'None'}

CRITICAL: The heading MUST be COMPLETELY DIFFERENT from already used headings.

The heading should:
- Be a section label, NOT the main title
- Be contextual to the position (left/right/center/row)
- Be concise and professional
- BE 100% UNIQUE (not in already used list)

Return ONLY the heading text, nothing else."""
            
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "Generate concise UNIQUE headings. Follow instructions exactly."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7 + (attempt * 0.1),  # Increase for variety
                    max_tokens=20
                )
                
                heading = response.choices[0].message.content.strip().strip('"\'')
                
                # âœ… FIX #3: Validate uniqueness
                if heading and heading not in used_subtitles:
                    logger.info(f"    Generated unique subtitle: {heading}")
                    return heading
                else:
                    logger.warning(f"    Subtitle '{heading}' already used, retrying (attempt {attempt + 1})...")
                    
            except Exception as e:
                logger.warning(f"Subtitle generation attempt {attempt+1} failed: {e}")
        
        # âœ… FIX #1: NO FALLBACK - Generate guaranteed unique
        base = purpose.split()[0] if purpose else "Section"
        counter = 1
        while f"{base} {counter}" in used_subtitles:
            counter += 1
        
        unique_heading = f"{base} {counter}"
        logger.info(f"    Using guaranteed unique: {unique_heading}")
        return unique_heading
    
    # Keep all other existing methods unchanged
    def _llm_deep_analysis(self, query: str, extracted_content: Optional[str] = None) -> Dict:
        """Existing - modified to use content"""

        context_str = f"Context from files:\n{extracted_content[:2000]}..." if extracted_content else ""

        prompt = f"""You are an expert business analyst. Analyze this presentation request:

"{query}"

{context_str}

Your task:
1. Understand the MAIN SUBJECT (company, topic, product, etc.)
2. Understand the CONTEXT (financial report, market analysis, product launch, etc.)
3. Identify ALL DISTINCT ASPECTS that should be covered
   - Think broadly: metrics, trends, comparisons, breakdowns, outlook, risks, etc.
   - Be comprehensive but avoid overlap
   - Aim for 6-10 distinct aspects

Return ONLY valid JSON:
{{
  "main_subject": "extracted main subject",
  "context": "type of analysis/report",
  "time_period": "if mentioned, else null",
  "aspects": [
    "First distinct aspect to cover",
    "Second distinct aspect to cover",
    "Third distinct aspect to cover"
  ]
}}

CRITICAL: Each aspect must be DIFFERENT. Think like you're planning a presentation outline."""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a business analyst. Return only valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,
                max_tokens=800,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            if not result.get('aspects') or len(result['aspects']) < 3:
                raise ValueError("Insufficient aspects returned")
            
            logger.info(f"    LLM identified {len(result['aspects'])} aspects")
            return result
            
        except Exception as e:
            logger.error(f"    LLM analysis failed: {e}")
            return {
                "main_subject": query.split()[0] if query else "Topic",
                "context": "analysis",
                "aspects": [f"Aspect {i+1}" for i in range(6)]
            }
    
    def _llm_determine_section_count(self, query: str, analysis: Dict, extracted_content: Optional[str] = None) -> int:
        """Existing - unchanged"""
        aspects = analysis.get('aspects', [])
        
        prompt = f"""Given this presentation request:
Query: "{query}"
Identified aspects: {len(aspects)}
{'Content available: Yes' if extracted_content else ''}

How many slides should this presentation have?

Consider:
- Complexity of topic
- Number of aspects to cover ({len(aspects)} aspects)
- Best practice (usually 6-12 slides for business presentations)

Return ONLY valid JSON:
{{
  "recommended_slides": 8,
  "reasoning": "brief explanation"
}}"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a presentation expert. Return only valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=200,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            count = result.get('recommended_slides', len(aspects))
            
            count = max(4, min(count, 15))
            logger.info(f"    LLM recommends {count} slides")
            return count
            
        except Exception as e:
            logger.error(f"    LLM count failed: {e}")
            return max(6, min(len(aspects), 10))
    
    def _dynamic_template_analysis(self, layouts: Dict) -> Dict:
        """Existing - unchanged"""
        usable = []
        chart_capable = []
        table_capable = []
        multi_content = []
        
        for idx, layout in layouts.items():
            if idx == 0:
                continue
            
            usable.append(idx)
            
            if layout.get('has_chart'):
                chart_capable.append(idx)
            if layout.get('has_table'):
                table_capable.append(idx)
            
            content_count = layout.get('content_count', 0)
            if content_count >= 3:
                multi_content.append(idx)
        
        return {
            'usable_layouts': usable,
            'chart_capable': chart_capable,
            'table_capable': table_capable,
            'multi_content': multi_content,
            'total': len(usable)
        }
    
    def _llm_generate_all_topics(self, query: str, analysis: Dict, 
                                  count: int, capabilities: Dict, extracted_content: Optional[str] = None) -> List[Dict]:
        """Existing - unchanged"""
        aspects = analysis.get('aspects', [])
        main_subject = analysis.get('main_subject', query)
        
        content_prompt = f"Base your topics on this content:\n{extracted_content[:3000]}..." if extracted_content else ""

        prompt = f"""Create {count} COMPLETELY DIFFERENT slide topics for this presentation:

Main Subject: {main_subject}
Context: {analysis.get('context', 'analysis')}
Aspects to cover: {json.dumps(aspects, indent=2)}

{content_prompt}

Template capabilities:
- Can display charts: {len(capabilities['chart_capable'])} layouts
- Can display tables: {len(capabilities['table_capable'])} layouts
- Can display multi-item content: {len(capabilities['multi_content'])} layouts

Your task:
1. Create {count} slide topics
2. Each topic must be UNIQUE - cover ONE distinct aspect
3. NO OVERLAP between topics
4. Suggest best content type for each (chart/table/icon_grid/kpi/bullets)

Return ONLY valid JSON array:
[
  {{
    "title": "Specific unique slide title",
    "purpose": "What this slide covers specifically",
    "best_content": "chart|table|icon_grid|kpi|bullets",
    "search_focus": "What to search for"
  }}
]

CRITICAL: All {count} topics must be DIFFERENT. Think like sections in a report."""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a presentation designer. Create diverse slide topics. Return only valid JSON array."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.9,
                max_tokens=2000,
                response_format={"type": "json_object"}
            )
            
            data = json.loads(response.choices[0].message.content)
            topics = data.get('slides', data.get('topics', data.get('sections', [])))
            
            if not isinstance(topics, list):
                topics = list(data.values())[0] if data else []
            
            if len(topics) >= count:
                logger.info(f"    LLM generated {len(topics)} topics")
                return topics[:count]
            
            raise ValueError(f"Only got {len(topics)} topics, needed {count}")
            
        except Exception as e:
            logger.error(f"    LLM topic generation failed: {e}")
            return [
                {
                    "title": f"Analysis {i+1}",
                    "purpose": aspects[i] if i < len(aspects) else f"Topic {i+1}",
                    "best_content": "bullets",
                    "search_focus": aspects[i] if i < len(aspects) else f"Topic {i+1}"
                }
                for i in range(count)
            ]
    
    def _assign_content_dynamically(self, specs: List, content_phs: List,
                                     blueprint: Dict, query: str, extracted_content: Optional[str] = None):
        """Existing - unchanged"""
        if not content_phs:
            return
        
        sorted_phs = sorted(content_phs, key=lambda p: p.get('area', 0), reverse=True)
        
        enforced = blueprint['content_type']
        purpose = blueprint['purpose']
        
        largest = sorted_phs[0]
        primary_type = self._determine_content_type(enforced, largest)
        
        search_query = self._llm_generate_search_query(
            query, purpose, primary_type, "primary", extracted_content
        )
        
        specs.append(PlaceholderContentSpec(
            placeholder_idx=largest['idx'],
            placeholder_type=largest['type'],
            content_type=primary_type,
            content_description=f"{purpose} - primary",
            search_queries=[search_query],
            position_group=largest.get('position_group', ''),
            role="content",
            dimensions={
                'width': largest.get('width', 0),
                'height': largest.get('height', 0),
                'area': largest.get('area', 0)
            }
        ))
        
        for i, ph in enumerate(sorted_phs[1:], 1):
            area = ph.get('area', 0)
            
            if area < 1:
                ct = 'kpi'
            elif area < 3:
                ct = 'bullets'
            else:
                ct = 'bullets'
            
            sq = self._llm_generate_search_query(query, purpose, ct, f"supporting_{i}", extracted_content)
            
            specs.append(PlaceholderContentSpec(
                placeholder_idx=ph['idx'],
                placeholder_type=ph['type'],
                content_type=ct,
                content_description=f"{purpose} - supporting",
                search_queries=[sq],
                position_group=ph.get('position_group', ''),
                role="content",
                dimensions={
                    'width': ph.get('width', 0),
                    'height': ph.get('height', 0),
                    'area': ph.get('area', 0)
                }
            ))
    
    def _determine_content_type(self, enforced: str, ph: Dict) -> str:
        """Existing - unchanged"""
        area = ph.get('area', 0)
        ph_type = ph.get('type', '')
        
        if enforced == 'chart':
            if 'CHART' in ph_type or area > 30:
                return 'column_chart'
        elif enforced == 'table':
            if 'TABLE' in ph_type or area > 40:
                return 'table'
        elif enforced == 'icon_grid' and area > 2:
            return 'icon_grid'
        elif enforced == 'kpi':
            return 'kpi'
        
        return 'bullets'
    
    def _llm_generate_search_query(self, main_query: str, purpose: str,
                                     content_type: str, role: str, extracted_content: Optional[str] = None) -> SearchQuery:
        """Existing - updated to handle content extraction source"""

        if extracted_content:
            # If we have extracted content, the "search query" becomes a "extraction instruction"
             return SearchQuery(
                query=f"Extract info about {purpose} for {content_type}",
                purpose=f"{purpose} - {role}",
                expected_source_type='extracted_content'
            )

        prompt = f"""Generate a specific search query:

Main topic: {main_query}
Slide purpose: {purpose}
Content type: {content_type}
Role: {role}

Create a search query that will find relevant data for this specific need.

Return ONLY the search query text, nothing else."""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Generate search queries."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=50
            )
            
            query_text = response.choices[0].message.content.strip().strip('"\'')
            
            return SearchQuery(
                query=query_text,
                purpose=f"{purpose} - {role}",
                expected_source_type='research'
            )
            
        except:
            return SearchQuery(
                query=f"{main_query} {content_type}",
                purpose=purpose,
                expected_source_type='research'
            )